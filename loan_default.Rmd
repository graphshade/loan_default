---
title: "Loan Default"
author: "Elvis Agbenyega"
output:
  html_document:
    df_print: paged
    toc: true
---


#  Import Libraries

```{r,warning=FALSE,message=FALSE}
library(tidyverse)
library(tidymodels)
library(vip)
library(skimr)
library(solitude) 
library(janitor)
library(ggpubr)
library(DALEX)
library(DALEXtra)
library(NeuralNetTools)
library(agua)
library(corrplot)
library(themis)
```

# Read Data

## Read in the data
```{r,warning=FALSE,message=FALSE}
#training set
loan_df <- read_csv("./data/loan_train.csv",
                    col_types = cols(.default = "?",
                                      id = col_character(),                                     
                                      member_id = col_character(),
                                    policy_code = col_character()))

#holding set
holdout_df <- read_csv("./data/loan_holdout.csv",
                       col_types = cols(.default = "?",
                                      id = col_character(),                                               
                                      member_id = col_character(),
                                     policy_code = col_character()))
loan_df %>% head()
holdout_df %>% head()
```

## Data preparation
```{r}
# ... data prep for loan df
loan_df <- loan_df %>% 
  mutate(issue_d = lubridate::my(issue_d),
         earliest_cr_line = lubridate::my(earliest_cr_line),
         last_pymnt_d = lubridate::my(last_pymnt_d))

### convert string for revol_util to decimal
loan_df$revol_util <- loan_df$revol_util %>% stringr::str_sub(1,-2) %>% as.numeric()
loan_df$revol_util <- loan_df$revol_util/100

### convert string for int_rate to decimal
loan_df$int_rate <- loan_df$int_rate %>% stringr::str_sub(1,-2) %>% as.numeric()
loan_df$int_rate <- loan_df$int_rate/100

### convert string for factor
loan_df <- loan_df %>%   
  mutate_if(is.character,as.factor) %>%
  mutate(loan_status = factor(loan_status)) 



# ... data prep for loan df
holdout_df <- holdout_df %>% 
  mutate(issue_d = lubridate::my(issue_d),
         earliest_cr_line = lubridate::my(earliest_cr_line),
         last_pymnt_d = lubridate::my(last_pymnt_d))

### convert string for revol_util to decimal
holdout_df$revol_util <- holdout_df$revol_util %>% stringr::str_sub(1,-2) %>% as.numeric()
holdout_df$revol_util <- holdout_df$revol_util/100

### convert string for int_rate to decimal
holdout_df$int_rate <- holdout_df$int_rate %>% stringr::str_sub(1,-2) %>% as.numeric()
holdout_df$int_rate <- holdout_df$int_rate/100

### convert string for factor
holdout_df <- holdout_df %>%   
  mutate_if(is.character,as.factor)
```


## Distribution of response variable

```{r}
loan_summary <- loan_df %>%
  count(loan_status) %>%
  mutate(pct = n/sum(n))

loan_summary

loan_summary  %>%
  ggplot(aes(x=loan_status,y=pct)) +
  geom_col()  + 
  scale_y_continuous(labels = label_percent()) + 
  geom_text(aes(label = paste(round(100*pct,2), "%", sep = "")) , vjust = 1.5, colour = "white" ) +
  labs(title="Loan default rate", x="Loan status", y="PCT")
```


# Exploratory Analysis

## Numerical values

### Box plot of numerical values
```{r}
loan_df %>% select_if(is.numeric) %>% names() -> num_cols

getboxplot <- function(col){
box_ <- loan_df %>% 
  ggplot(aes(x = loan_status, y=!!as.name(col), fill=loan_status)) +
  geom_boxplot()+
  labs(title = paste0("boxplot for ", col),
     y = col,
     x="loan status") +
  coord_flip()
  return(box_)}

for(col in num_cols){
  chart_ = getboxplot(col = col)
  print(chart_)
}
```

### Descriptive statistics table for numerical values

```{r}

getstat <- function(col){
stat_ <- loan_df %>%                               # Summary by group using dplyr
  group_by(loan_status) %>% 
  summarize(min = min(!!as.name(col),na.rm=TRUE),
            q1 = quantile(!!as.name(col), 0.25,na.rm=TRUE),
            median = median(!!as.name(col),na.rm=TRUE),
            mean = mean(!!as.name(col),na.rm=TRUE),
            q3 = quantile(!!as.name(col), 0.75,na.rm=TRUE),
            max = max(!!as.name(col),na.rm=TRUE)) %>% 
    as.tibble() %>% 
  mutate(var = col)
return(stat_)}

a <- vector("list", 1)

for(col in num_cols){
  a[[col]] <- getstat(col)}

data_des <- do.call("rbind",a) 
data_des %>% head()


```

### Correlation matrix of numerical values

```{r,fig.height=10,fig.width=10}

num_df <- loan_df %>% select (
 loan_amnt, funded_amnt, funded_amnt_inv, int_rate, installment,
 annual_inc, dti, delinq_2yrs, fico_range_low, fico_range_high,
 inq_last_6mths, mths_since_last_delinq, mths_since_last_record,
 open_acc, pub_rec, revol_bal, revol_util, total_acc, 
 out_prncp, out_prncp_inv, total_rec_late_fee, last_pymnt_amnt,
 pub_rec_bankruptcies
)
cc = cor(num_df %>% na.omit())

corrplot(cc)
```

## Categorical values

```{r}

getbarchart<- function(col){
loan_df %>%
  count(!!as.name(col),loan_status) %>% 
  ggplot(aes(x=!!as.name(col),y=n, fill=loan_status)) +
  geom_col(position = "fill")  + 
  scale_y_continuous(labels = label_percent()) + 
  labs(title= paste0("Loan default by ",col), x=col, y="Proportion") +
  geom_hline(yintercept = 0.15)+
  coord_flip()
}

char_cols <- c("term", "grade","sub_grade", "emp_length","home_ownership","verification_status",
                "pymnt_plan","policy_code","application_type","purpose","addr_state")
for(col in char_cols){
bar_ <- getbarchart(col)
print(bar_)}
```



```{r}
loan_df %>% select_if(is.factor) %>% names() -> char_cols

getbar <- function(col){
box_ <- loan_df %>% 
  ggplot(aes(x = loan_status, y=!!as.name(col))) +
  geom_boxplot()+
  labs(title = paste0("boxplot for ", col),
     y = col,
     x="loan status")
  coord_flip()
  return(box_)}

getboxplot("int_rate")

for(col in num_cols){
  chart_ = getboxplot(col = col)
  print(chart_)
}
```


### New features
```{r}

loan_df <- loan_df %>% mutate(
  fico_band = fico_range_high - fico_range_low, ### feature for fico band = fico upper - figo lower
  revol_income_ratio = revol_bal/annual_inc 
)

holdout_df <- holdout_df %>% mutate(
  fico_band = fico_range_high - fico_range_low, ### feature for fico band = fico upper - figo lower
  revol_income_ratio = revol_bal/annual_inc 
)

```




# Model building

## Train Test Split 

```{r}
set.seed(42)

train_test_spit<- initial_split(loan_df, prop = 0.7, strata=loan_status)

train <- training(train_test_spit)
test  <- testing(train_test_spit)


sprintf("Train PCT : %1.2f%%", nrow(train)/ nrow(loan_df) * 100)
sprintf("Test  PCT : %1.2f%%", nrow(test)/ nrow(loan_df) * 100)

```

## Model evaluation strategy

```{r}

#function to predict given model and threshold
predict_set <- function(workflow_fit, dataset, threshold = 0.5){
  scored <- predict(workflow_fit, dataset, type="prob") %>% 
    mutate(.pred_class = as.factor(ifelse(.pred_default>=threshold, "default","current"))) %>% 
    bind_cols(.,dataset)
  return(scored)}


#function to evaluate model and compute model gain
evaluate_set <- function(scored_data, model_name, datasplit = "training", event_label = "loan_status", event_level="second"){
  
  multi_metric <- metric_set(accuracy, precision, recall, mn_log_loss, specificity , roc_auc)
  scored_data %>% 
    multi_metric(truth = !!as.name(event_label), 
            predicted = .pred_default, 
            estimate = .pred_class,
            event_level = event_level) %>%
    mutate(datasplit=datasplit,
           model_name = model_name, 
           .estimate = round(.estimate, 4)) %>%  
    pivot_wider(names_from = .metric, values_from=.estimate) %>% 
    mutate(fpr = 1- specificity) -> eval
return(eval)}
```


## Receipe
```{r}

#recipe
loan_recipe <- recipe(loan_status ~ term + emp_length + int_rate+installment+
                            dti+fico_range_low+fico_range_high+last_pymnt_amnt +
                            loan_amnt + funded_amnt +  grade + sub_grade + annual_inc,data = train)%>%
  step_impute_median(all_numeric_predictors())  %>%
  step_unknown(all_nominal_predictors()) %>%
  step_novel(all_nominal_predictors()) %>% 
  step_dummy(all_nominal_predictors(), one_hot = TRUE) %>% 
  themis::step_downsample(loan_status, under_ratio = 3)

```


## Logistic Model

### Model specification

```{r}
#Model specification
log_spec <- logistic_reg() %>%
  set_mode("classification") %>%
  set_engine("glm")
#Model workflow
log_workflow <- workflow() %>%
  add_recipe(loan_recipe) %>%
  add_model(log_spec) %>%
  fit(train)
## -- check out your parameter estimates ...
metrics <- tidy(log_workflow) %>%
  mutate_at(c("estimate", "std.error", "statistic", "p.value"),round, 4)

metrics
```

### Logistic Model - Evaluation

```{r}
scored_train_log <- predict_set(workflow_fit = log_workflow,
                                dataset = train,
                                threshold = 0.5)
scored_train_log

eval_metrics_train_log <- evaluate_set(scored_data = scored_train_log, 
                                       model_name = "logistic", 
                                       datasplit = "training",
                                       event_label = "loan_status",
                                       event_level = "second")

scored_test_log <- predict_set(workflow_fit = log_workflow,
                               dataset = test,
                               threshold = 0.5)
scored_test_log

eval_metrics_test_log <- evaluate_set(scored_data = scored_test_log, 
                                      model_name = "logistic", 
                                      datasplit = "testing",
                                      event_label = "loan_status",
                                      event_level = "second")

eval_metrics_log <- eval_metrics_train_log %>% bind_rows(eval_metrics_test_log)
eval_metrics_log
```


## Random Forest - Tuned

### Model specification

```{r}
set.seed(456)
rf_tune_spec <- rand_forest(
  mtry = tune(),
  trees = 500,
  min_n = tune()) %>%
  set_mode("classification") %>%
  set_engine("ranger", importance = "permutation")

#workflow
rf_tune_wf <- workflow() %>%
  add_recipe(loan_recipe) %>%
  add_model(rf_tune_spec)

#vfold samples
set.seed(234)
trees_folds <- vfold_cv(train, v = 3)

#enable parallel processing
doParallel::registerDoParallel(cores = 3)

#set up grid  
set.seed(456)
rf_grid <- grid_random(
  mtry(range(5,12)),
  min_n(),
  size = 10)

rf_grid

#metric set
tune_metric <- metric_set(roc_auc)


#tune
set.seed(456)
regular_res <- tune_grid(
  rf_tune_wf,
  resamples = trees_folds,
  grid = rf_grid,
  metrics = tune_metric
)

regular_res

#view metrics
regular_res %>%
  collect_metrics() %>%
  filter(.metric == "roc_auc") %>%
  mutate(min_n = factor(min_n)) %>%
  ggplot(aes(mtry, mean, color = min_n)) +
  geom_line(alpha = 0.5, size = 1.5) +
  geom_point() +
  labs(y = "AUC")


#select best parameters
best_auc <- select_best(regular_res, "roc_auc")

#select best model
final_rf <- finalize_model(
  rf_tune_spec,
  best_auc
)

final_rf

#final workflow
final_rf_wf_tuned <- workflow() %>%
  add_recipe(loan_recipe) %>%
  add_model(final_rf) %>% 
  fit(train)
  


saveRDS(final_rf_wf_tuned, "./final_rf_wf_tuned.rds")

#Variable Importance
final_rf_wf_tuned %>%
  extract_fit_parsnip() %>%
  vip(30)

# # -- RF model & workflow 
# rf_model <- rand_forest(
#   trees = 100, ) %>% 
#   set_engine("ranger",num.threads = 8, importance = "permutation") %>% 
#   set_mode("classification" )
# 
# rf_workflow_fit <- workflow() %>%
#   add_recipe(rf_recipe) %>%
#   add_model(rf_model) %>% 
#   fit(train)

```

### Random Forest Tuned - Evaluation

```{r}
#rf_wf <- readRDS("./rand_forest_final_tune.rds")
scored_train_rf_tuned <- predict_set(final_rf_wf_tuned, train)
scored_test_rf_tuned <- predict_set(final_rf_wf_tuned, test)

# write_csv(scored_train_rf, "./results/scored_train_rf.csv")
# write_csv(scored_test_rf, "./results/scored_test_rf.csv")

eval_metrics_train_rf_tuned <- evaluate_set(scored_data = scored_train_rf_tuned, 
                                            model_name = "Random forest - tuned", 
                                            datasplit = "training",
                                            event_label = "loan_status",
                                            event_level = "second")
eval_metrics_test_rf_tuned <- evaluate_set(scored_data = scored_test_rf_tuned, 
                                           model_name = "Random forest - tuned", 
                                           datasplit = "testing",
                                           event_label = "loan_status",
                                           event_level = "second")

eval_metrics_rf_tune <- eval_metrics_train_rf_tuned %>% 
  bind_rows(eval_metrics_test_rf_tuned)
eval_metrics_rf_tune
```


## XGBoost - Tuned

### Model specification

```{r}
set.seed(456)
xgb_tune_spec <- boost_tree(trees=tune(), 
                        learn_rate = tune(),
                        tree_depth = tune()) %>%
  set_engine("xgboost", importance="permutation") %>%
  set_mode("classification")

#workflow
xgb_tune_wf <- workflow() %>%
  add_recipe(loan_recipe) %>%
  add_model(xgb_tune_spec)

#vfold samples
set.seed(234)
trees_folds <- vfold_cv(train, v = 3)

#enable parallel processing
doParallel::registerDoParallel(cores = 3)

#set up grid  
# set.seed(456)
# rf_grid <- grid_random(
#   mtry(range(5,12)),
#   min_n(),
#   size = 10)
# 
# rf_grid

#metric set
tune_metric <- metric_set(roc_auc)

#tune
set.seed(456)
xgb_tuned <- tune_bayes(
  xgb_tune_wf,
  resamples = trees_folds,
  metrics = tune_metric,
  # Generate five at semi-random to start
  initial = 5,
  iter = 20, 
  # How to measure performance?
  control = control_bayes(no_improve = 5, verbose = TRUE)
)

xgb_tuned

#select best parameters
best_auc <- select_best(xgb_tuned, "roc_auc")

#select best model
final_xgb <- finalize_model(
  xgb_tune_spec,
  best_auc
)

final_xgb

#final workflow
final_xgb_tuned <- workflow() %>%
  add_recipe(loan_recipe) %>%
  add_model(final_xgb) %>% 
  fit(train)
  


saveRDS(final_xgb_tuned, "./final_xgb_tuned.rds")

#Variable Importance
final_xgb_tuned %>%
  extract_fit_parsnip() %>%
  vip(30)

# # -- RF model & workflow 
# rf_model <- rand_forest(
#   trees = 100, ) %>% 
#   set_engine("ranger",num.threads = 8, importance = "permutation") %>% 
#   set_mode("classification" )
# 
# rf_workflow_fit <- workflow() %>%
#   add_recipe(rf_recipe) %>%
#   add_model(rf_model) %>% 
#   fit(train)

```

```{r}
xgb_tuned %>%  collect_metrics() %>% 
  filter(.metric == "roc_auc")

xgb_tuned %>%
  collect_metrics() %>%
  ggplot(aes(learn_rate, mean, color = .metric)) +
  geom_errorbar(aes(
    ymin = mean - std_err,
    ymax = mean + std_err
  ),
  alpha = 0.5
  ) +
  geom_line(size = 1.5) +
  facet_wrap(~.metric, scales = "free", nrow = 2) +
  scale_x_log10() +
  theme(legend.position = "none")


xgb_tuned %>%
  collect_metrics() %>%
  ggplot(aes(trees, mean, color = .metric)) +
  geom_errorbar(aes(
    ymin = mean - std_err,
    ymax = mean + std_err
  ),
  alpha = 0.5
  ) +
  geom_line(size = 1.5) +
  facet_wrap(~.metric, scales = "free", nrow = 2) +
  scale_x_log10() +
  theme(legend.position = "none")
```


### XGBoost Tuned - Evaluation

```{r}
#rf_wf <- readRDS("./rand_forest_final_tune.rds")
scored_train_xgb_tuned <- bind_cols(
  predict(final_xgb_tuned, train,type="prob"), 
  predict(final_xgb_tuned,train, type="class"),
  train) %>% 
  mutate(part = "train")

scored_test_xgb_tuned <- bind_cols(
  predict(final_xgb_tuned, test,type="prob"), 
  predict(final_xgb_tuned,test, type="class"),
  test) %>% 
  mutate(part = "test")


# write_csv(scored_train_rf, "./results/scored_train_rf.csv")
# write_csv(scored_test_rf, "./results/scored_test_rf.csv")

eval_metrics_train_xgb_tuned <- evaluate_set(scored_data = scored_train_xgb_tuned, 
                                            model_name = "XGB - tuned", 
                                            datasplit = "training",
                                            event_label = "loan_status",
                                            event_level = "second")
eval_metrics_test_xgb_tuned <- evaluate_set(scored_data = scored_test_xgb_tuned, 
                                           model_name = "XGB - tuned", 
                                           datasplit = "testing",
                                           event_label = "loan_status",
                                           event_level = "second")

eval_metrics_xgb_tune <- eval_metrics_train_xgb_tuned %>% 
  bind_rows(eval_metrics_test_xgb_tuned)
eval_metrics_xgb_tune
```


## Neural Nets - Tuned

### Model specification

```{r}

#recipe for neueral nets
loan_recipe_mlp <- recipe(loan_status ~ term + emp_length + int_rate+installment+
                            dti+fico_range_low+fico_range_high+last_pymnt_amnt +
                            loan_amnt + funded_amnt +  grade + sub_grade + annual_inc,data = train)%>%
  step_impute_median(all_numeric_predictors())  %>%
  step_unknown(all_nominal_predictors()) %>%
  step_novel(all_nominal_predictors()) %>% 
  step_dummy(all_nominal_predictors(), one_hot = TRUE) %>% 
  themis::step_downsample(loan_status, under_ratio = 3) %>%  
  step_nzv(all_predictors()) %>% 
  step_scale(all_predictors())


# set.seed(456)
mlp_tune_spec <- mlp(epochs = 10,learn_rate = 0.1,hidden_units = tune()) %>%
  set_mode("classification") %>%
  set_engine("nnet")

#workflow
mlp_tune_wf <- workflow() %>%
  add_recipe(loan_recipe_mlp) %>%
  add_model(mlp_tune_spec)

#vfold samples
set.seed(234)
trees_folds <- vfold_cv(train, v = 3)

#enable parallel processing
doParallel::registerDoParallel(cores = 3)

#set up grid
set.seed(456)
# mlp_grid <- grid_random(
#     learning_rate())
# 
# mlp_grid

#metric set
tune_metric <- metric_set(roc_auc)


#tune
set.seed(456)
mlp_tuned <- tune_grid(
  mlp_tune_wf,
  resamples = trees_folds,
  metrics = tune_metric
)

mlp_tuned


#select best parameters
best_auc <- select_best(mlp_tuned, "roc_auc")

#select best model
final_mlp <- finalize_model(
  mlp_tune_spec,
  best_auc
)

final_mlp

#final workflow
final_mlp_tuned <- workflow() %>%
  add_recipe(loan_recipe_mlp) %>%
  add_model(final_mlp) %>%
  fit(train)



saveRDS(final_rf_wf_tuned, "./final_rf_wf_tuned.rds")

#Variable Importance
visualize_network <- function(nn_workflow){
  # extract model and plot 
  mod1 <- nn_workflow$fit$fit$fit
  plotnet(mod1) 

}

visualize_network(final_mlp_tuned)


```

### Neural Nets - Evaluation

```{r}
#rf_wf <- readRDS("./rand_forest_final_tune.rds")
scored_train_mlp_tuned <- bind_cols(
  predict(final_mlp_tuned, train,type="prob"), 
  predict(final_mlp_tuned,train, type="class"),
  train) %>% 
  mutate(part = "train")

scored_test_mlp_tuned <- bind_cols(
  predict(final_mlp_tuned, test,type="prob"), 
  predict(final_mlp_tuned,test, type="class"),
  test) %>% 
  mutate(part = "test")

eval_metrics_train_mlp_tuned <- evaluate_set(scored_data = scored_train_mlp_tuned, 
                                            model_name = "MLP - tuned", 
                                            datasplit = "training",
                                            event_label = "loan_status",
                                            event_level = "second")
eval_metrics_test_mlp_tuned <- evaluate_set(scored_data = scored_test_mlp_tuned, 
                                           model_name = "MLP - tuned", 
                                           datasplit = "testing",
                                           event_label = "loan_status",
                                           event_level = "second")

eval_metrics_mlp_tune <- eval_metrics_train_mlp_tuned %>% 
  bind_rows(eval_metrics_test_mlp_tuned)
eval_metrics_mlp_tune
```



## Model Results

```{r}
all_metrics <- bind_rows(eval_metrics_log,
                         eval_metrics_rf_tune, 
                         eval_metrics_xgb_tune, 
                         eval_metrics_mlp_tune)
all_metrics %>% write_csv("./metrics_all.csv")
all_metrics
```

Confusion Matrix
```{r}

scored_test_xgb_tuned %>%
  conf_mat(loan_status, .pred_class) %>%
  autoplot( type = "heatmap") +
  labs(title="Test Confusion Matrix")

```



# Evaluation 

## Current Operating Range

```{r}
# ROC Curve  
bind_rows(scored_train_xgb_tuned %>% mutate(datasplit = "training"), 
          scored_test_xgb_tuned  %>% mutate(datasplit = "testing")) %>%
  group_by(datasplit) %>%
  roc_curve(loan_status, .pred_default, event_level="second") %>%
  autoplot() +
  geom_vline(xintercept = 0.0247, # 5% FPR 
             color = "red",
             linetype = "longdash") +
  geom_vline(xintercept = 0.05, # 5% FPR 
             color = "yellow",
             linetype = "longdash") +
  geom_vline(xintercept = 0.25,   # 25% FPR 
             color = "blue",
             linetype = "longdash") +
  geom_vline(xintercept = 0.75,   # 75% FPR 
             color = "green",
             linetype = "longdash") +
  labs(title = "RF ROC Curve" , x = "FPR(1 - specificity)", y = "TPR(recall)") 
```


```{r}
 #histogram of probability of default
scored_test_xgb_tuned %>%
  ggplot(aes(.pred_default, fill = loan_status)) +
  geom_histogram(bins = 50) +
  geom_vline(xintercept = 0.5, color = "red") +
  labs(
    title = paste("Distribution of the Probabilty of loan default") ,
    x = ".pred_default",
    y = "count",
    fill = "Loan status"
  ) 
```


## Operating at 5% False Positive Rate (Threshould = 0.316	)

```{r}
# operating range 0 - 10% 
operating_range <- scored_test_xgb_tuned %>%
  roc_curve(loan_status, .pred_default, event_level="second")  %>%
  mutate(
    fpr = round((1 - specificity), 2),
    tpr = round(sensitivity, 3),
    score_threshold =  round(.threshold, 3)
  ) %>%
  group_by(fpr) %>%
  summarise(threshold = round(mean(score_threshold),3),
            tpr = mean(tpr)) %>%
  filter(fpr <= 0.5)
# operating range table 
operating_range
```

## True positive rate and cost savings

```{r}

threshold <- c(0.979,0.941,0.892,0.838,0.771,0.7,0.64,0.573,0.503)

a <- vector("list", 1)

for(col in 1:length(threshold)){
  scored_ <- predict_set(final_xgb_tuned, test, threshold = threshold[col])
  a[[col]] <- evaluate_set(scored_data = predict_set(final_xgb_tuned, test, threshold = threshold[col]), 
                           model_name = "XGB", 
                           datasplit = "testing",
                           event_label = "loan_status",
                           event_level = "second")}

opt_df <- do.call("rbind",a) 
opt_df$threshold <- threshold

# cost savings

##amount lost to per default
loan_df %>% 
  group_by(loan_status) %>% 
  summarise(loan_amt_def = sum(loan_amnt)) %>% 
  filter(loan_status == "default")

total_amt_default = 53066925
  
opt_df$saving = opt_df$recall *total_amt_default

opt_df 

```


```{r}
# ROC Curve  
bind_rows(scored_train_rf_fpr %>% mutate(datasplit = "training"), 
          scored_test_rf_fpr  %>% mutate(datasplit = "testing")) %>%
  group_by(datasplit) %>%
  roc_curve(event_label, .pred_fraud) %>%
  autoplot() +
  geom_vline(xintercept = 0.0037, # 5% FPR 
             color = "red",
             linetype = "longdash") +
  geom_vline(xintercept = 0.05, # 5% FPR 
             color = "yellow",
             linetype = "longdash") +
  geom_vline(xintercept = 0.25,   # 25% FPR 
             color = "blue",
             linetype = "longdash") +
  geom_vline(xintercept = 0.75,   # 75% FPR 
             color = "green",
             linetype = "longdash") +
  labs(title = "RF ROC Curve" , x = "FPR(1 - specificity)", y = "TPR(recall)") 
```


```{r}
 #histogram of probability of fraud 
scored_test_rf_fpr%>%
  ggplot(aes(.pred_fraud, fill = event_label)) +
  geom_histogram(bins = 50) +
  geom_vline(xintercept = 0.316, color = "red") +
  labs(
    title = paste("Distribution of the Probabilty of FRAUD:", "RF Model") ,
    x = ".pred_fraud",
    y = "count"
  ) 
```




# Explaining the best model

## Global Interpretability  - PDP
```{r}
rf_workflow_fit <- final_xgb_tuned
rf_workflow_fit %>% 
  pull_workflow_fit() %>%
  vip(10)

rf_explainer <- explain_tidymodels(
  rf_workflow_fit,
  data = train ,
  y = train$loan_default ,
  verbose = TRUE
)

pdp_lpmnt <- model_profile(
  rf_explainer,
  variables = "last_pymnt_amnt"
)

pdp_inst <- model_profile(
  rf_explainer,
  variables = "installment"
)

pdp_int <- model_profile(
  rf_explainer,
  variables = "int_rate"
)

pdp_dti <- model_profile(
  rf_explainer,
  variables = "dti"
)

pdp_inc <- model_profile(
  rf_explainer,
  variables = "annual_inc"
)

pdp_fund <- model_profile(
  rf_explainer,
  variables = "loan_amnt"
)

plot(pdp_fund) + 
  labs(title = "PDP - Loan Amount", 
       x="Loan amount", 
       y="avg impact on prediction",
       subtitle = "")


plot(pdp_lpmnt) + 
  labs(title = "PDP - Last Payment Amount", 
       x="Last Payment Amount", 
       y="avg impact on prediction",
       subtitle = "")

plot(pdp_inst) + 
  labs(title = "PDP - Installment", 
       x="Installment", 
       y="avg impact on prediction",
       subtitle = "")

plot(pdp_int) + 
  labs(title = "PDP - Interest rate", 
       x="Insteret rate", 
       y="avg impact on prediction",
       subtitle = "")

plot(pdp_dti) + 
  labs(title = "PDP - Debt-Income Ratio", 
       x="Debt-Income ratio", 
       y="avg impact on prediction",
       subtitle = "")

plot(pdp_inc) + 
  labs(title = "PDP - Annual Income", 
       x="Annual income", 
       y="average impact on prediction", subtitle="",
       ) 


pdp_fund <- model_profile(
  rf_explainer,
  variables = "loan_amnt"
)

plot(pdp_fund) + 
  labs(title = "PDP - Last Payment Amount", 
       x="Last Payment Amount", 
       y="avg impact on prediction",
       subtitle = "")


```


## Prediction Explainer  - Breakdown

### Top best and bottom worst performance predictions
```{r}
train_sample <- test %>% 
  select(term, emp_length,int_rate,installment,
         dti,fico_range_low,fico_range_high,last_pymnt_amnt,
         loan_amnt,funded_amnt,grade, sub_grade,annual_inc) %>%
  sample_frac(0.1) # take a 10% sample or less

rf_explainer <- explain_tidymodels(
  rf_workflow_fit,
  data = train_sample ,
  y = train_sample$loan_status ,
  verbose = TRUE
)


# Top 5 TP highest scoring defaults 
top_5_tp <- scored_test_xgb_tuned %>%
  filter(.pred_class == loan_status) %>%
  filter(loan_status == "default") %>%
  slice_max(order_by = .pred_default, n=5)

# Top 5 FP highest scoring defaults 
top_5_fp <- scored_test_xgb_tuned %>%
  filter(.pred_class == loan_status) %>%
  filter(loan_status != "default") %>%
  slice_max(order_by = .pred_default, n=5)

# Bottom 5 FN lowest scoring defaults 
bottom_5_fn <- scored_test_xgb_tuned %>%
  filter(.pred_class == loan_status) %>%
  filter(loan_status == "default") %>%
  slice_min(order_by = .pred_default, n=5)


```

### Local Explainer - breakdown

```{r}


explain_prediction_shap <- function(single_record){
  
# explainer
record_shap <- predict_parts(explainer = rf_explainer, 
                               new_observation = single_record,
                               type="shap")

# predicted probs
prediction_prob <- single_record[,".pred_default"] %>% 
  mutate(.pred_default = round(.pred_default,3)) %>% 
  pull() 

# step 3. plot it..  
record_shap %>% 
  plot() +
  labs(title=paste("SHAP Explainer:",prediction_prob),
       x = "contribution",
       y = "record") ->shap_plot 

print(shap_plot)
}
# example TP 5 records
for (row in 1:nrow(top_5_tp)) {
    s_record <- top_5_tp[row,]
    explain_prediction_shap(s_record)
} 

for (row in 1:nrow(bottom_5_fn)) {
    s_record <- bottom_5_fn[row,]
    explain_prediction_shap(s_record)
} 

for (row in 1:nrow(top_5_fp)) {
    s_record <- top_5_fp[row,]
    explain_prediction_shap(s_record)
} 


```





##	Anomaly detection â€“ 

```{r}
# recipe
iso_recipe <- recipe( ~ int_rate+installment+
                            dti+fico_range_low+fico_range_high+last_pymnt_amnt +
                            loan_amnt + funded_amnt +  annual_inc
                       , train) %>% 
  step_impute_mean(all_predictors()) %>% 
  prep()

# bake
iso_prep <- bake(iso_recipe, train)

# isoforest
iso_forest <- isolationForest$new(
  sample_size = 2048,
  num_trees = 100,
  max_depth = 12)

# fit
iso_forest$fit(iso_prep)

# predict
pred_train <- iso_forest$predict(iso_prep)

#sumarize
pred_train %>%
  summarise(n=n(),
            min = min(average_depth),
            max = max(average_depth),
            mean = mean(average_depth),
            min_score =  min(anomaly_score),
            max_score = max(anomaly_score),
            mean_score= mean(anomaly_score),
    
  )

# pl0t
pred_train %>%
  ggplot(aes(average_depth)) +
  geom_histogram(bins=20) + 
  geom_vline(xintercept = 10, linetype="dotted", 
                color = "blue", size=1.5) + 
  labs(title="Isolation Forest Average Tree Depth")

# plot
pred_train %>%
  ggplot(aes(anomaly_score)) +
  geom_histogram(bins=20) + 
  geom_vline(xintercept = 0.7, linetype="dotted", 
                color = "blue", size=1.5) + 
  labs(title="Isolation Forest Anomaly Score Above 0.7")

# Who is anomalous?
bind_cols(pred_train, train) %>% 
  filter(anomaly_score>0.7) 

# make a surrogate model 
synth_train <- bind_cols(pred_train, iso_prep) %>%
  mutate(synthetic_target = as.factor(
           if_else(anomaly_score >= 0.7,"default","current"))
         ) %>%
  select(-average_depth, -anomaly_score, -id)

synth_train
# fit a model 
fmla <- as.formula(paste("synthetic_target ~ ", paste(synth_train %>% colnames(), collapse= "+")))

outlier_tree <- decision_tree(min_n=2, tree_depth=3, cost_complexity = .01) %>%
  set_mode("classification") %>%
  set_engine("rpart") %>%
  fit(fmla, data=synth_train)

outlier_tree$fit
```

# Global Anomaly Rules 
```{r}
library(rpart.plot)
library(rpart)
anomaly_rules <- rpart.rules(outlier_tree$fit,roundint=FALSE, extra = 4, cover = TRUE, clip.facs = TRUE) %>% clean_names() %>%
  #filter(anomaly=="Anomaly") %>%
  mutate(rule = "IF") 


rule_cols <- anomaly_rules %>% select(starts_with("x_")) %>% colnames()

for (col in rule_cols){
anomaly_rules <- anomaly_rules %>%
    mutate(rule = paste(rule, !!as.name(col)))
}

anomaly_rules %>%
  as.data.frame() %>%
  filter(synthetic_target != "current") %>%
  mutate(rule = paste(rule, " THEN ", synthetic_target )) %>%
  mutate(rule = paste(rule," coverage ", cover)) %>%
  select( rule)

anomaly_rules %>%
  as.data.frame() %>%
  filter(synthetic_target == "current") %>%
  mutate(rule = paste(rule, " THEN ", synthetic_target )) %>%
  mutate(rule = paste(rule," coverage ", cover)) %>%
  select( rule)

train %>% 
  filter(installment >= 952 & funded_amnt >= 30263  )

```
## explain 5 anomalies 

```{r}

# Who is anomalous?
pred_train <- iso_forest$predict(iso_prep)
pred_train <- bind_cols(pred_train, iso_prep) %>%
  mutate(synthetic_target = as.factor(
           if_else(anomaly_score >= 0.7,"default","current"))
         ) 


local_explainer <- function(ID){
  
  fmla <- as.formula(paste("anomaly ~ ", paste(iso_prep %>% colnames(), collapse= "+")))
  
  pred_train %>%
    mutate(anomaly= as.factor(if_else(id==ID, "Anomaly", "Normal"))) -> local_df
  
  local_tree <-  decision_tree(mode="classification",
                              tree_depth = 3,
                              min_n = 1,
                              cost_complexity=0) %>%
                set_engine("rpart") %>%
                    fit(fmla,local_df )
  
  local_tree$fit
  
  #rpart.rules(local_tree$fit, extra = 4, cover = TRUE, clip.facs = TRUE)
  rpart.plot(local_tree$fit, roundint=FALSE, extra=3) %>% print()
  
  anomaly_rules <- rpart.rules(local_tree$fit, extra = 4, cover = TRUE, clip.facs = TRUE) %>% clean_names() %>%
    filter(anomaly=="Anomaly") %>%
    mutate(rule = "IF") 
  
  
  rule_cols <- anomaly_rules %>% select(starts_with("x_")) %>% colnames()
  
  for (col in rule_cols){
  anomaly_rules <- anomaly_rules %>%
      mutate(rule = paste(rule, !!as.name(col)))
  }
  
  as.data.frame(anomaly_rules) %>%
    select(rule, cover) %>%
    print()
}

pred_train %>%
  slice_max(order_by=anomaly_score,n=5) %>%
  pull(id) -> anomaly_vect

for (anomaly_id in anomaly_vect){
  local_explainer(anomaly_id)
}
```


# Holdout prediction

```{r}
predict_set(final_xgb_tuned, holdout_df) %>% 
  dplyr::select(id, loan_status = .pred_default) %>% 
  write_csv("./kaggle7.csv")
```
